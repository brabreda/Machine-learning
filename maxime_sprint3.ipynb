{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 1 classes.\n",
      "Found 199 images belonging to 1 classes.\n",
      "(None, 128, 128, 3)\n",
      "(None, 4, 4, 256)\n",
      "(None, 4, 4, 256)\n",
      "(None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the input shape and number of classes\n",
    "INPUT_SHAPE = (128, 128, 3)  # Assume 128x128 RGB images\n",
    "NUM_CLASSES = 2  # Food or not food\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Set the directory containing the images\n",
    "image_dir = 'food_images_2'\n",
    "\n",
    "# Create an ImageDataGenerator object with the preprocessing function\n",
    "image_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Use the generator to load the images from the directory\n",
    "train_data_gen = image_generator.flow_from_directory(image_dir,\n",
    "                                                     target_size=(128, 128),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     class_mode='binary',\n",
    "                                                     batch_size=32,\n",
    "                                                     subset='training')\n",
    "val_data_gen = image_generator.flow_from_directory(image_dir,\n",
    "                                                   target_size=(128, 128),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32,\n",
    "                                                   subset='validation')\n",
    "\n",
    "# Get the images and labels from the generator\n",
    "x_train, y_train = next(train_data_gen)\n",
    "x_val, y_val = next(val_data_gen)\n",
    "\n",
    "\n",
    "# Define the encoder\n",
    "encoder_input = layers.Input(shape=INPUT_SHAPE)\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(encoder_input)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Dropout(0.5)(x)  # Add dropout for regularization\n",
    "encoder_output = layers.MaxPooling2D(2, padding='same')(x)\n",
    "\n",
    "# Create the encoder model\n",
    "encoder = Model(encoder_input, encoder_output, name='encoder')\n",
    "\n",
    "# Define the decoder\n",
    "decoder_input = encoder_output\n",
    "x = layers.Conv2D(256, 3, activation='relu', padding='same')(decoder_input)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "x = layers.UpSampling2D(2)(x)\n",
    "decoder_output = layers.Conv2D(3, 3, activation='softmax', padding='same')(x)\n",
    "\n",
    "# Print encoder and decoder shapes\n",
    "print(encoder_input.shape)\n",
    "print(encoder_output.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unvisited input tensors that are disconnected from the outputs: [<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'input_79')>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [93], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m autoencoder \u001b[39m=\u001b[39m Model([encoder_input, decoder_input], decoder_output)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/functional.py:163\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    158\u001b[0m         [\n\u001b[1;32m    159\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    160\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    161\u001b[0m         ]\n\u001b[1;32m    162\u001b[0m     ):\n\u001b[0;32m--> 163\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39;49mclone_graph_nodes(\n\u001b[1;32m    164\u001b[0m             inputs, outputs\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/functional_utils.py:155\u001b[0m, in \u001b[0;36mclone_graph_nodes\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone_graph_nodes\u001b[39m(inputs, outputs):\n\u001b[1;32m    137\u001b[0m     \u001b[39m\"\"\"Clone the `Node` between the inputs and output tensors.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[39m    This function is used to create a new functional model from any intermediate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m      to create a new functional model.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     nodes_to_clone \u001b[39m=\u001b[39m find_nodes_by_inputs_and_outputs(inputs, outputs)\n\u001b[1;32m    156\u001b[0m     cloned_inputs \u001b[39m=\u001b[39m []\n\u001b[1;32m    157\u001b[0m     cloned_outputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/functional_utils.py:129\u001b[0m, in \u001b[0;36mfind_nodes_by_inputs_and_outputs\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m end_ids \u001b[39m!=\u001b[39m end_ids_found:\n\u001b[1;32m    126\u001b[0m     unvisited_inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m         kt \u001b[39mfor\u001b[39;00m kt \u001b[39min\u001b[39;00m end_keras_tensors \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(kt) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m end_ids_found\n\u001b[1;32m    128\u001b[0m     ]\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unvisited input tensors that are disconnected from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe outputs: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(unvisited_inputs)\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m nodes_in_graph\n",
      "\u001b[0;31mValueError\u001b[0m: Found unvisited input tensors that are disconnected from the outputs: [<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'input_79')>]"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "autoencoder = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(loss='binary_crossentropy', \n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model_100\" is incompatible with the layer: expected shape=(None, 4, 4, 256), found shape=(None, 128, 128, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mfit([x_train, x_train], y_train,\n\u001b[1;32m      2\u001b[0m                           batch_size\u001b[39m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      3\u001b[0m                           epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      4\u001b[0m                           validation_data\u001b[39m=\u001b[39m([x_val, x_val], y_val))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4l/gsvsrpxd2kqb4f6v1wy203b80000gn/T/__autograph_generated_filevuh8si0i.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 1 of layer \"model_100\" is incompatible with the layer: expected shape=(None, 4, 4, 256), found shape=(None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit([x_train, x_train], y_train,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=10,\n",
    "                          validation_data=([x_val, x_val], y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder model\n",
    "encoder_model = Model(encoder_input, encoder_output)\n",
    "\n",
    "# Define the decoder model\n",
    "decoder_model = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the encoder and decoder separately\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history_encoder \u001b[39m=\u001b[39m encoder_model\u001b[39m.\u001b[39mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39mBATCH_SIZE, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, validation_data\u001b[39m=\u001b[39m(x_val, y_val), verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m history_decoder \u001b[39m=\u001b[39m decoder_model\u001b[39m.\u001b[39mfit(y_train, x_train, batch_size\u001b[39m=\u001b[39mBATCH_SIZE, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, validation_data\u001b[39m=\u001b[39m(y_val, x_val), verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:3690\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   3685\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3686\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3687\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[1;32m   3688\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3689\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3690\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3691\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3692\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3693\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3694\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# Train the encoder and decoder separately\n",
    "history_encoder = encoder_model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=10, validation_data=(x_val, y_val), verbose=2)\n",
    "history_decoder = decoder_model.fit(y_train, x_train, batch_size=BATCH_SIZE, epochs=10, validation_data=(y_val, x_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights of the autoencoder\n",
    "autoencoder.save_weights('autoencoder_weights.h5')\n",
    "\n",
    "# Use the encoder to generate a lower-dimensional representation of the input images\n",
    "X_encoded = encoder.predict(x_train)\n",
    "\n",
    "# Train a classifier on the lower-dimensional representation of the input images\n",
    "classifier = Sequential()\n",
    "classifier.add(Flatten(input_shape=X_encoded.shape[1:]))  # Flatten the input\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "classifier.add(Dropout(0.5))  # Add dropout for regularization\n",
    "classifier.add(Dense(32, activation='relu'))\n",
    "classifier.add(Dropout(0.5))  # Add dropout for regularization\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.fit(X_encoded, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Save the classifier\n",
    "classifier.save('classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights of the autoencoder\n",
    "autoencoder.save_weights('autoencoder_weights.h5')\n",
    "\n",
    "# Use the encoder to generate a lower-dimensional representation of the input images\n",
    "X_encoded = encoder.predict(x_train)\n",
    "\n",
    "# Train a classifier on the lower-dimensional representation of the input images\n",
    "classifier = Sequential()\n",
    "classifier.add(Flatten(input_shape=X_encoded.shape[1:]))  # Flatten the input\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "classifier.add(Dropout(0.5))  # Add dropout for regularization\n",
    "classifier.add(Dense(32, activation='relu'))\n",
    "classifier.add(Dropout(0.5))  # Add dropout for regularization\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.fit(X_encoded, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Save the classifier\n",
    "classifier.save('classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/gsvsrpxd2kqb4f6v1wy203b80000gn/T/ipykernel_8046/1061904928.py:10: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image_data = imageio.imread('./tripadvisor_images_2/23487213_1.jpg')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 16, 16, 8), found shape=(None, 128, 128, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X_encoded \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mpredict(resized_image)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Use the classifier to make a prediction on the lower-dimensional representation of the input image\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m prediction \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_encoded)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m prediction \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFood image\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4l/gsvsrpxd2kqb4f6v1wy203b80000gn/T/__autograph_generated_fileamm60fe9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 16, 16, 8), found shape=(None, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Load the autoencoder and the classifier\n",
    "#autoencoder = load_model('autoencoder.h5')\n",
    "#classifier = load_model('classifier.h5')\n",
    "\n",
    "# Load the image and preprocess it\n",
    "image_data = imageio.imread('./tripadvisor_images_2/23487213_1.jpg')\n",
    "# Resize the image to the same size as the training images\n",
    "resized_image = resize(image_data, (128, 128))\n",
    "# Normalize the image data\n",
    "resized_image /= 255.\n",
    "# Add an extra dimension to the array to match the expected input shape of the model\n",
    "resized_image = np.expand_dims(resized_image, axis=0)\n",
    "\n",
    "\n",
    "# Use the autoencoder to generate a lower-dimensional representation of the input image\n",
    "X_encoded = autoencoder.predict(resized_image)\n",
    "\n",
    "# Use the classifier to make a prediction on the lower-dimensional representation of the input image\n",
    "prediction = classifier.predict(X_encoded)[0][0]\n",
    "\n",
    "if prediction > 0.5:\n",
    "    print('Food image')\n",
    "else:\n",
    "    print('Not a food image')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
