{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy plot shows the accuracy of the model on the training set for each epoch. This can give you an idea of how well the model is able to learn from the training data. Ideally, you want to see the training accuracy increase over time, as this indicates that the model is improving.\n",
    "\n",
    "The training loss plot shows the loss of the model on the training set for each epoch. This can give you an idea of how well the model is performing on the training data. Ideally, you want to see the training loss decrease over time, as this indicates that the model is improving.\n",
    "\n",
    "Together, these plots can give you useful insights into the performance of the model on the training data. For example, if you see that the training accuracy is increasing but the training loss is not decreasing, this could indicate that the model is overfitting to the training data and not generalizing well to new data. On the other hand, if you see that the training accuracy is not increasing but the training loss is decreasing, this could indicate that the model is underfitting and not able to learn effectively from the training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOTHER OPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 16:26:20.811486: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-15 16:26:27.284916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the 'food_images' dataset\n",
    "# (assumes the data is stored as a collection of image files)\n",
    "food_images = []\n",
    "food_labels = []\n",
    "for image_path in glob.glob('food_images_2/*.jpg'):\n",
    "  image = tf.keras.preprocessing.image.load_img(image_path, grayscale=False)\n",
    "  food_images.append(image)\n",
    "  # Set the label for all images to 'food'\n",
    "  food_labels.append(1)\n",
    "\n",
    "\n",
    "# Preprocess the images by resizing them and converting them to RGB\n",
    "image_size = (256, 256)  # set desired image size\n",
    "# Convert the images to arrays with the correct dimensions\n",
    "food_images = [tf.image.convert_image_dtype(image, tf.float32) for image in food_images]\n",
    "\n",
    "# Convert the images to arrays with the correct dimensions  \n",
    "food_images = [tf.convert_to_tensor(image, dtype=tf.float32) for image in food_images]\n",
    "\n",
    "# Convert the images and labels to arrays\n",
    "#food_images = np.array(food_images)\n",
    "#food_labels = np.array(food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape all images to the desired size\n",
    "food_images = [tf.image.resize(image, image_size) for image in food_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    food_images, food_labels, test_size=0.1, shuffle=True)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_data, train_labels, test_size=0.1, shuffle=True)\n",
    "\n",
    "\n",
    "input_shape = train_data[0].shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add convolutional layers with corrrect input shape\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
    "                                activation='relu', input_shape=input_shape))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same',\n",
    "                              activation='relu'))\n",
    "\n",
    "# Add pooling layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add dense layers\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Check the shape of the data\n",
    "print(train_data[0].shape)\n",
    "print(val_data[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a dataset from the training data and labels\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "# Repeat the dataset, shuffle it, and batch the data\n",
    "train_dataset = train_dataset.repeat().shuffle(len(train_data)).batch(32)\n",
    "# Create a dataset from the validation data and labels\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "# Repeat the dataset and batch the data\n",
    "val_dataset = val_dataset.repeat().batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the images and labels to tensors\n",
    "train_data = tf.convert_to_tensor(train_data, dtype=tf.float32)\n",
    "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.convert_to_tensor(val_data, dtype=tf.float32)\n",
    "val_labels = tf.convert_to_tensor(val_labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tensors to numpy arrays\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Add an additional dimension to the arrays\n",
    "train_data = np.expand_dims(train_data, axis=-1)\n",
    "val_data = np.expand_dims(val_data, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 80s 3s/step - loss: 0.0324 - accuracy: 0.9604 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 78s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 79s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 78s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 79s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 79s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 79s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 79s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 78s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 81s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create a history object\n",
    "#history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
    "\n",
    "# Train the model using the fit() method\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#history = model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_loss, val_acc = model.evaluate(val_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "# predictions ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "# Load one image from the trip_images dataset\n",
    "image = tf.keras.preprocessing.image.load_img('tripadvisor_images/694642_4.jpg', grayscale=False)\n",
    "# Preprocess the image by resizing it and converting it to RGB\n",
    "image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "image = tf.image.resize(image, image_size)\n",
    "# Add an additional dimension to the image\n",
    "image = np.expand_dims(image, axis=0)\n",
    "# Make a prediction on the image\n",
    "prediction = model.predict(image)\n",
    "# Print the prediction\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImage file not found: \u001b[39m\u001b[39m{\u001b[39;00mimage_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Convert the images to arrays with the correct dimensions\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m restaurant_images \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mconvert_image_dtype(image, tf\u001b[39m.\u001b[39mfloat32) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m restaurant_images]\n\u001b[1;32m     18\u001b[0m \u001b[39m# Shape all images to the desired size\u001b[39;00m\n\u001b[1;32m     19\u001b[0m restaurant_images \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(image, image_size) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m restaurant_images]\n",
      "Cell \u001b[0;32mIn [22], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImage file not found: \u001b[39m\u001b[39m{\u001b[39;00mimage_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Convert the images to arrays with the correct dimensions\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m restaurant_images \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mconvert_image_dtype(image, tf\u001b[39m.\u001b[39;49mfloat32) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m restaurant_images]\n\u001b[1;32m     18\u001b[0m \u001b[39m# Shape all images to the desired size\u001b[39;00m\n\u001b[1;32m     19\u001b[0m restaurant_images \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(image, image_size) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m restaurant_images]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# IMport cv2, os\n",
    "import cv2\n",
    "import os\n",
    "# Use the trained model to classify the images in the restaurant_images dataset as \"food\" or \"non-food\"\n",
    "# First, preprocess the images in the same way as the training data\n",
    "restaurant_images = []\n",
    "for image_path in glob.glob('tripadvisor_images/*.jpg'):\n",
    "    # Check if the image file exists before trying to load it\n",
    "    if os.path.isfile(image_path):\n",
    "        # Use OpenCV to load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        restaurant_images.append(image)\n",
    "    else:\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "\n",
    "# Convert the images to arrays with the correct dimensions\n",
    "restaurant_images = [tf.image.convert_image_dtype(image, tf.float32) for image in restaurant_images]\n",
    "# Shape all images to the desired size\n",
    "restaurant_images = [tf.image.resize(image, image_size) for image in restaurant_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x167d7fdd0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m restaurant_images \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m image_path \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39mtripadvisor_images/*.jpg\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mpreprocessing\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mload_img(image_path, grayscale\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     restaurant_images\u001b[39m.\u001b[39mappend(image)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Convert the images to arrays with the correct dimensions\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/image_utils.py:423\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m         path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(path\u001b[39m.\u001b[39mresolve())\n\u001b[1;32m    422\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 423\u001b[0m         img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39;49mopen(io\u001b[39m.\u001b[39;49mBytesIO(f\u001b[39m.\u001b[39;49mread()))\n\u001b[1;32m    424\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpath should be path-like or io.BytesIO, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(path)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py:3147\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[39mfor\u001b[39;00m message \u001b[39min\u001b[39;00m accept_warnings:\n\u001b[1;32m   3146\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message)\n\u001b[0;32m-> 3147\u001b[0m \u001b[39mraise\u001b[39;00m UnidentifiedImageError(\n\u001b[1;32m   3148\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcannot identify image file \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (filename \u001b[39mif\u001b[39;00m filename \u001b[39melse\u001b[39;00m fp)\n\u001b[1;32m   3149\u001b[0m )\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x167d7fdd0>"
     ]
    }
   ],
   "source": [
    "# Use the trained model to classify the images in the restaurant_images dataset as \"food\" or \"non-food\"\n",
    "# First, preprocess the images in the same way as the training data\n",
    "restaurant_images = []\n",
    "for image_path in glob.glob('tripadvisor_images/*.jpg'):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, grayscale=False)\n",
    "    restaurant_images.append(image)\n",
    "# Convert the images to arrays with the correct dimensions\n",
    "restaurant_images = [tf.image.convert_image_dtype(image, tf.float32) for image in restaurant_images]\n",
    "# Convert the images to arrays with the correct dimensions\n",
    "restaurant_images = [tf.convert_to_tensor(image, dtype=tf.float32) for image in restaurant_images]\n",
    "# Shape all images to the desired size\n",
    "restaurant_images = [tf.image.resize(image, image_size) for image in restaurant_images]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first image in the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(restaurant_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the preprocessed images using the trained model\n",
    "predictions = model.predict(restaurant_images)\n",
    "\n",
    "# The model outputs a probability for each class (food and non-food)\n",
    "# For each image, the class with the higher probability is the predicted label\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the history data\n",
    "history_dict = history.history\n",
    "\n",
    "# Plot the training accuracy\n",
    "plt.plot(history_dict['accuracy'])\n",
    "plt.plot(history_dict['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history_dict['loss'])\n",
    "plt.plot(history_dict['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
