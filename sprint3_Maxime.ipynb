{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'images' must have either 3 or 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Preprocess the images by resizing them and converting them to RGB\u001b[39;00m\n\u001b[1;32m     22\u001b[0m image_size \u001b[39m=\u001b[39m (\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m)  \u001b[39m# set desired image size\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m food_images \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(image, image_size) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m food_images]\n\u001b[1;32m     24\u001b[0m \u001b[39m#food_images = [tf.image.rgb_to_grayscale(image) for image in food_images]\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m# Convert the images and labels to arrays\u001b[39;00m\n\u001b[1;32m     27\u001b[0m food_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(food_images)\n",
      "Cell \u001b[0;32mIn [22], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Preprocess the images by resizing them and converting them to RGB\u001b[39;00m\n\u001b[1;32m     22\u001b[0m image_size \u001b[39m=\u001b[39m (\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m)  \u001b[39m# set desired image size\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m food_images \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mresize(image, image_size) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m food_images]\n\u001b[1;32m     24\u001b[0m \u001b[39m#food_images = [tf.image.rgb_to_grayscale(image) for image in food_images]\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m# Convert the images and labels to arrays\u001b[39;00m\n\u001b[1;32m     27\u001b[0m food_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(food_images)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/ops/image_ops_impl.py:1450\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1448\u001b[0m   images \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mexpand_dims(images, \u001b[39m0\u001b[39m)\n\u001b[1;32m   1449\u001b[0m \u001b[39melif\u001b[39;00m images\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m-> 1450\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mimages\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m must have either 3 or 4 dimensions.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1452\u001b[0m _, height, width, _ \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mas_list()\n\u001b[1;32m   1454\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: 'images' must have either 3 or 4 dimensions."
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the 'food_images' dataset\n",
    "# (assumes the data is stored as a collection of image files)\n",
    "food_images = []\n",
    "food_labels = []\n",
    "for image_path in glob.glob('food_images/*.jpg'):\n",
    "  image = tf.keras.preprocessing.image.load_img(image_path, grayscale=True)\n",
    "  food_images.append(image)\n",
    "  # Set the label for all images to 'food'\n",
    "  food_labels.append(1)\n",
    "\n",
    "# Preprocess the images by resizing them and converting them to RGB\n",
    "image_size = (256, 256)  # set desired image size\n",
    "food_images = [tf.image.resize(image, image_size) for image in food_images]\n",
    "#food_images = [tf.image.rgb_to_grayscale(image) for image in food_images]\n",
    "\n",
    "# Convert the images and labels to arrays\n",
    "food_images = np.array(food_images)\n",
    "food_labels = np.array(food_labels)\n",
    "\n",
    "# Use one-hot encoding to transform the labels into shape (None, 10)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "food_labels = encoder.fit_transform(food_labels.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    food_images, food_labels, test_size=0.1, shuffle=True)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_data, train_labels, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m               optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(train_data, train_labels, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, validation_data\u001b[39m=\u001b[39m(val_data, val_labels))\n\u001b[1;32m     26\u001b[0m \u001b[39m# Evaluate the model on the validation data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m val_loss, val_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(val_data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4l/gsvsrpxd2kqb4f6v1wy203b80000gn/T/__autograph_generated_file_dsba177.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
    "                              activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same',\n",
    "                              activation='relu'))\n",
    "\n",
    "# Add pooling layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add dense layers\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_loss, val_acc = model.evaluate(val_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy plot shows the accuracy of the model on the training set for each epoch. This can give you an idea of how well the model is able to learn from the training data. Ideally, you want to see the training accuracy increase over time, as this indicates that the model is improving.\n",
    "\n",
    "The training loss plot shows the loss of the model on the training set for each epoch. This can give you an idea of how well the model is performing on the training data. Ideally, you want to see the training loss decrease over time, as this indicates that the model is improving.\n",
    "\n",
    "Together, these plots can give you useful insights into the performance of the model on the training data. For example, if you see that the training accuracy is increasing but the training loss is not decreasing, this could indicate that the model is overfitting to the training data and not generalizing well to new data. On the other hand, if you see that the training accuracy is not increasing but the training loss is decreasing, this could indicate that the model is underfitting and not able to learn effectively from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the history data\n",
    "history_dict = history.history\n",
    "\n",
    "# Plot the training accuracy\n",
    "plt.plot(history_dict['accuracy'])\n",
    "plt.plot(history_dict['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history_dict['loss'])\n",
    "plt.plot(history_dict['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOTHER OPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'only_food_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[39m# Train the model on the \"only_food_images\" set\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m model\u001b[39m.\u001b[39mfit(only_food_images, labels, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Evaluate the model on the \"restaurant_images\" set\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model\u001b[39m.\u001b[39mevaluate(restaurant_images, labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'only_food_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Here is an example of how you could train a CNN model to classify images as \"food\" or \"not food\" using TensorFlow Keras:\n",
    "\n",
    "# Import necessary modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional and pooling layers\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add a flattening layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add a final output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the \"only_food_images\" set\n",
    "model.fit(only_food_images, labels, epochs=10)\n",
    "\n",
    "# Evaluate the model on the \"restaurant_images\" set\n",
    "model.evaluate(restaurant_images, labels)\n",
    "\n",
    "#In this code, the CNN model is first defined using the Sequential class from TensorFlow Keras. The model consists of two convolutional layers followed by a pooling layer, a flattening layer, and two dense layers. The model is then compiled using the compile method, specifying the adam optimizer and binary_crossentropy loss function.\n",
    "\n",
    "#The model is then trained on the \"only_food_images\" set using the fit method. The number of epochs can be adjusted as needed. Finally, the model's performance is evaluated on the \"restaurant_images\" set using the evaluate method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
