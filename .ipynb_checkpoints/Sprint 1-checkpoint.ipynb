{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5b3949",
   "metadata": {},
   "source": [
    "# Machine learning - sprint 1\n",
    "authors: Allart Ewoud, Van Hees Maxime, Breda Bram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae9144",
   "metadata": {},
   "source": [
    "#### GET AN INTIAL FEEL OF THE DATA? MOET DIT ER NOG BIJ OF NIET? --> LABO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b43ddb",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and read csv using pandas\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa072c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "original_df = pd.read_csv(\"tripadvisor_dataset/restaurant_listings.csv\")\n",
    "\n",
    "# display the data and see how it formulated\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c2121",
   "metadata": {},
   "source": [
    "## Split in test & train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509fe0a",
   "metadata": {},
   "source": [
    "The goal of machine learning is to build models on train data that are able to make predictions on unseen test data. So we first try to split our data into a trainset and a test set before we move on to the other steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(original_df, random_state=0, train_size = 0.8)\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df = df_train.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c1c33",
   "metadata": {},
   "source": [
    "## Data clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ba231",
   "metadata": {},
   "source": [
    "First we start with cleaning of the less complicated data. This includes the collumns general rating, number of reviews and rank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445dff3",
   "metadata": {},
   "source": [
    "### General rating, number of reviews & rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general rating\n",
    "df[\"general rating\"] = df_train[\"general rating\"].apply(lambda x: float(str(x).split(' ')[0]))\n",
    "df[\"general rating\"] = pd.to_numeric(df[\"general rating\"])\n",
    "\n",
    "# number of reviews\n",
    "df[\"number of reviews\"] = df_train[\"number of reviews\"].apply(lambda x: int(str(x).split(' ')[0]))\n",
    "df[\"number of reviews\"] = pd.to_numeric(df[\"number of reviews\"])\n",
    "\n",
    "# rank\n",
    "df[\"rank\"] = df_train[\"rank\"].str.split(\"#\").str[1]\n",
    "df[\"rank\"] = pd.to_numeric(df[\"rank\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e1f41",
   "metadata": {},
   "source": [
    "### Restaurants with no reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc113fc8",
   "metadata": {},
   "source": [
    "2 options:\n",
    "\n",
    "- we remove the restaurants that have no reviews, and thus nu general rating. But will this impact the model we will train later on? \n",
    "\n",
    "```df2 = df.loc[(df['number of reviews'] == 0) & (df['general rating'] == -1.0)]```\n",
    "\n",
    "- we don't remove them and assume the model will learn by itself that these entries aren't that useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98e00d",
   "metadata": {},
   "source": [
    "### Price range\n",
    "A collumn that is a bit more complicated is price range, this collumn will be split in 2, after this the average is taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = df_train[\"price range\"].str.split(\" - \").str[1]\n",
    "upper_bound = upper_bound.str.split('€').str[1]\n",
    "upper_bound = pd.to_numeric(upper_bound)\n",
    "\n",
    "lower_bound = df_train[\"price range\"].str.split(\" - \").str[0]\n",
    "lower_bound = lower_bound.str.split('€').str[1]\n",
    "lower_bound = pd.to_numeric(lower_bound)\n",
    "\n",
    "sn.displot(upper_bound)\n",
    "sn.displot(lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "average = (upper_bound-lower_bound)/2\n",
    "\n",
    "transformer = preprocessing.FunctionTransformer(pd.cut, kw_args={'bins': 5, 'labels': [0, 1, 2, 3, 4], 'retbins': True})\n",
    "avg_quantfied = transformer.fit_transform(average)\n",
    "\n",
    "#visualize the data\n",
    "sn.displot(avg_quantfied[0])\n",
    "\n",
    "df['price range'] =  pd.to_numeric(avg_quantfied[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c50dd",
   "metadata": {},
   "source": [
    "### Food, service & value rating\n",
    "As we can see in the next scatter matrix (diagonal), food, service & value rating have a lot of -1 values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b530e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df[[\"food rating\",\"service rating\",\"value rating\"]], figsize = (8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca62623",
   "metadata": {},
   "source": [
    "This is something that needs to be solved, -1 is not a valid rating. There are a few option that can solve this issue: \n",
    "- Drop the rows with a -1 value\n",
    "- Drop the column \n",
    "- Change the value to a meaningfull value like zero, mean, medain, etc.\n",
    "\n",
    "Dropping the rows would result in alot of data being lost. Droping the column may result an in a a valueble feature being lost, so the best option is changing it for a meanigfull value. In this case median and mean are 2 candidats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1567db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df[\"service rating\"].loc[df[\"service rating\"] != -1].mean()\n",
    "df[\"service rating\"] = df[\"service rating\"].replace(-1,mean)\n",
    "\n",
    "mean = df[\"food rating\"].loc[df[\"food rating\"] != -1].mean()\n",
    "df[\"food rating\"] = df[\"food rating\"].replace(-1,mean)\n",
    "\n",
    "mean = df[\"value rating\"].loc[df[\"value rating\"] != -1].mean()\n",
    "df[\"value rating\"] = df[\"value rating\"].replace(-1,mean)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60e49b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6fc1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df[[\"food rating\",\"service rating\",\"value rating\"]], figsize = (12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22ccd0",
   "metadata": {},
   "source": [
    "### Meals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577cef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting all different types off meals\n",
    "types = []\n",
    "for i in df_train['meals'].fillna(value=\"\"):\n",
    "    types.extend(map(lambda x: x.strip(), i.split(\",\")))\n",
    "types = set(types)\n",
    "\n",
    "\n",
    "# For every type we are going to create a collumn that represents the type\n",
    "for i in types:\n",
    "    if i != \"\":\n",
    "        df[i] = df_train[\"meals\"].apply(lambda x: str(x)).apply(lambda x: int(i in x))\n",
    "\n",
    "# displays full table\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a4a12",
   "metadata": {},
   "source": [
    "#### <font color='red'>VRAAG: kunnen we de opties reduceren, bv brunch & breakfast? Later hiernaar kijken</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41c8c5",
   "metadata": {},
   "source": [
    "### Cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = []\n",
    "for i in df_train['cuisines'].fillna(value=\"\"):\n",
    "    types.extend(map(lambda x: x.strip(), i.split(\",\")))\n",
    "types = set(types)\n",
    "print(\"Amount of different cuisines:\",len(types))\n",
    "\n",
    "# prints the amout of times a cuisine occurs in the data\n",
    "# set _print on True to enable printing of frequencies\n",
    "_print = True\n",
    "\n",
    "\n",
    "freq = {}\n",
    "for i in types:  \n",
    "    if i != \"\":\n",
    "        freq[i] = df_train[\"cuisines\"].apply(lambda x: str(x)).apply(lambda x: int(i in x)).sum()\n",
    "\n",
    "\n",
    "#print(\"\\n\")\n",
    "#print(\"-\"*20, \"frequency tabel\", \"-\"*20) \n",
    "#for key, value in freq.items():\n",
    "#    print('{:<25}'.format(key ), '{:>4}'.format(value) , \"times\")\n",
    "percentile75 = np.quantile(list(freq.values()), 0.75)\n",
    "percentile50 = np.quantile(list(freq.values()), 0.5)\n",
    "\n",
    "print(\"50-percentile:\",percentile50)\n",
    "print(\"75-percentile:\",percentile75)\n",
    "\n",
    "\n",
    "freq = { key:value for (key,value) in freq.items() if value > percentile50}\n",
    "\n",
    "for (key,value) in freq.items():\n",
    "    if key != \"\":\n",
    "        df[key] = df_train[\"cuisines\"].apply(lambda x: int(key in str(x)))\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5201de8",
   "metadata": {},
   "source": [
    "The boxplot shows the distribution of the frequencies of the cuisines. Here we can see that a lot of cuisines occur only a few times. This may presents an oppertunity to reduce these to a categorie like \"others\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5469246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(4, 10))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "bp = ax.boxplot(freq.values())\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e0fcb",
   "metadata": {},
   "source": [
    "### Address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026ffcd",
   "metadata": {},
   "source": [
    "The address field has the following structure in most cases:\n",
    "    1. Streetname + number + \",\"\n",
    "    2. City + corresponding postal code\n",
    "    3. Country (here Belgium in all cases)\n",
    "Upon closer inspection we can see that sometimes field 1. and 2. are comma-separted, sometimes not.\n",
    "The number behind the streetname sometimes consists of two numbers (can be split with ' ' or '-' or '/' or ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_train\n",
    "\n",
    "# Let's start by stripping 'Belgium'\n",
    "df2[\"address\"] = df2[\"address\"].str.rstrip(\"Belgium\")\n",
    "# Enkel nog de gemeente/stad overhouden\n",
    "#df2[\"address\"] = df2[\"address\"].str.split(\",\").str[1]\n",
    "#df2[\"address\"] = df2[\"address\"].str.split(\" \").str[0]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df, figsize = (12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5973a6c",
   "metadata": {},
   "source": [
    "### Restaurant features\n",
    "\n",
    "Extract different restaurant feautures from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict that holds all restaurant feautures and how much they appear\n",
    "feature_types = {}\n",
    "for i in df_train['restaurant features'].fillna(value=\"\"):\n",
    "    for f in i.split(','):\n",
    "        if i != \"\":\n",
    "            if f.strip() in feature_types.keys():\n",
    "                feature_types[f.strip()] += 1\n",
    "            else:\n",
    "                feature_types[f.strip()] = 1\n",
    "           \n",
    "print(\"Amount of features:\" , len(feature_types.keys()))\n",
    "\n",
    "# omzetten naar dataframe\n",
    "df_features = pd.DataFrame(feature_types, index=[0]).transpose()\n",
    "df_features.columns = ['Amount']\n",
    "df_features.sort_values(['Amount'], ascending=False, inplace=True)\n",
    "df_features.plot(kind='barh', figsize=(12,12))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce15542",
   "metadata": {},
   "source": [
    "### Special Diets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f76ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which special diets exist in the data\n",
    "diet_types = {}\n",
    "for i in df_train['special diets'].fillna(value=\"\"):\n",
    "    for f in i.split(','):\n",
    "            if f.strip() in diet_types.keys():\n",
    "                diet_types[f.strip()] += 1\n",
    "            else:\n",
    "                diet_types[f.strip()] = 1\n",
    "           \n",
    "print(\"Amount of diets:\" , len(diet_types.keys()))\n",
    "print(diet_types)\n",
    "\n",
    "# check if available diet options have influence on the average rating per restaurant\n",
    "diet_avg_review = {}\n",
    "for d in diet_types.keys():\n",
    "    if len(df_train[df_train['special diets'].str.contains(d) == True]) >=  100: #only use data of a diet type if there are more than 100 restaurants with that diet type\n",
    "        diet_avg_review[d] = df[df_train['special diets'].str.contains(d) == True]['general rating'].mean()\n",
    "print('Average review score per diet type',diet_avg_review)\n",
    "df_diets = pd.Series(diet_avg_review).rename({'': 'No diets specified in data'})\n",
    "df_diets.sort_values(ascending=False).plot(kind='barh', figsize=(10,2), title='Average review score per diet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a70226",
   "metadata": {},
   "source": [
    "The graph above shows that restaurants with vegan and gluten free options have a higher average review score. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
