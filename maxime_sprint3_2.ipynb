{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 1 classes.\n",
      "Found 199 images belonging to 1 classes.\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the input shape and number of classes\n",
    "INPUT_SHAPE = (128, 128, 3)  # Assume 128x128 RGB images\n",
    "NUM_CLASSES = 2  # Food or not food\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Set the directory containing the images\n",
    "image_dir = 'food_images_2'\n",
    "\n",
    "# Create an ImageDataGenerator object with the preprocessing function\n",
    "image_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Use the generator to load the images from the directory\n",
    "train_data_gen = image_generator.flow_from_directory(image_dir,\n",
    "                                                     target_size=(128, 128),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     class_mode='binary',\n",
    "                                                     batch_size=32,\n",
    "                                                     subset='training')\n",
    "val_data_gen = image_generator.flow_from_directory(image_dir,\n",
    "                                                   target_size=(128, 128),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32,\n",
    "                                                   subset='validation')\n",
    "\n",
    "# Get the images and labels from the generator\n",
    "x_train, y_train = next(train_data_gen)\n",
    "x_val, y_val = next(val_data_gen)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output and add a fully connected layer for classification\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax')) \n",
    "\n",
    "# print model output shape\n",
    "print(model.output_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 3)\n",
      "(32,)\n",
      "(32, 128, 128, 3)\n",
      "(32,)\n",
      "[[[0.18431373 0.227451   0.2509804 ]\n",
      "  [0.12941177 0.16470589 0.18431373]\n",
      "  [0.1137255  0.14901961 0.16862746]\n",
      "  ...\n",
      "  [0.92549026 0.8980393  0.8588236 ]\n",
      "  [0.91372555 0.8980393  0.8862746 ]\n",
      "  [0.8352942  0.8352942  0.8352942 ]]\n",
      "\n",
      " [[0.15294118 0.19607845 0.21960786]\n",
      "  [0.11764707 0.15294118 0.17254902]\n",
      "  [0.10980393 0.14509805 0.16470589]\n",
      "  ...\n",
      "  [0.7294118  0.7058824  0.65882355]\n",
      "  [0.854902   0.8431373  0.81568635]\n",
      "  [0.8235295  0.8196079  0.8000001 ]]\n",
      "\n",
      " [[0.16470589 0.20784315 0.23137257]\n",
      "  [0.12156864 0.15686275 0.1764706 ]\n",
      "  [0.09803922 0.13333334 0.15294118]\n",
      "  ...\n",
      "  [0.5411765  0.50980395 0.4666667 ]\n",
      "  [0.6039216  0.5882353  0.54509807]\n",
      "  [0.6666667  0.65882355 0.6117647 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.8470589  0.81568635 0.80392164]\n",
      "  [0.8470589  0.8078432  0.8000001 ]\n",
      "  [0.8313726  0.7960785  0.7686275 ]\n",
      "  ...\n",
      "  [0.5647059  0.6862745  0.8078432 ]\n",
      "  [0.5686275  0.6901961  0.8117648 ]\n",
      "  [0.5764706  0.69803923 0.8196079 ]]\n",
      "\n",
      " [[0.86666673 0.8352942  0.82745105]\n",
      "  [0.8431373  0.80392164 0.7960785 ]\n",
      "  [0.8352942  0.8000001  0.7725491 ]\n",
      "  ...\n",
      "  [0.54901963 0.67058825 0.79215693]\n",
      "  [0.5568628  0.6784314  0.8000001 ]\n",
      "  [0.57254905 0.69411767 0.81568635]]\n",
      "\n",
      " [[0.8862746  0.85098046 0.854902  ]\n",
      "  [0.8313726  0.79215693 0.7843138 ]\n",
      "  [0.83921576 0.80392164 0.77647066]\n",
      "  ...\n",
      "  [0.4901961  0.6117647  0.73333335]\n",
      "  [0.5176471  0.6392157  0.7607844 ]\n",
      "  [0.5254902  0.64705884 0.7686275 ]]]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((32, 2) vs (32, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(x_train[\u001b[39m0\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39m(x_val, y_val), epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4l/gsvsrpxd2kqb4f6v1wy203b80000gn/T/__autograph_generated_filenpv5r9_9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((32, 2) vs (32, 1)).\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Evaluate the model on the test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest loss:\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest accuracy:\u001b[39m\u001b[39m'\u001b[39m, accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Convert the predictions to a one-hot encoded form\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert the true labels to a one-hot encoded form\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Create the confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
